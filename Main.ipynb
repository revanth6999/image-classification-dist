{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfa5b07-a82d-4e4d-b5aa-e30ad81df011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tNot using distributed mode\n",
      "2024/11/19 12:56:57\tINFO\t__main__\tNamespace(config='configs/densenet_from_wide_resnet.yaml', device='mps', run_log='log/test2.log', start_epoch=0, seed=None, disable_cudnn_benchmark=False, test_only=False, student_only=False, log_config=False, world_size=1, dist_url='env://', adjust_lr=False)\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `RandomCrop` from `torchvision.transforms`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `RandomCrop` from `torchvision.transforms` with {'kwargs': {'size': 32, 'padding': 4}}\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `RandomHorizontalFlip` from `torchvision.transforms`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `RandomHorizontalFlip` from `torchvision.transforms` with {'kwargs': {'p': 0.5}}\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `ToTensor` from `torchvision.transforms`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `ToTensor` from `torchvision.transforms` with {}\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `Normalize` from `torchvision.transforms`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `Normalize` from `torchvision.transforms` with {'kwargs': {'mean': [0.5070754, 0.48655024, 0.44091907], 'std': [0.26733398, 0.25643876, 0.2761503]}}\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `Compose` from `torchvision.transforms`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `Compose` from `torchvision.transforms` with {'kwargs': {'transforms': [RandomCrop(size=(32, 32), padding=4), RandomHorizontalFlip(p=0.5), ToTensor(), Normalize(mean=[0.5070754, 0.48655024, 0.44091907], std=[0.26733398, 0.25643876, 0.2761503])]}}\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tGetting `CIFAR100` from `torchvision.datasets`\n",
      "2024/11/19 12:56:57\tINFO\ttorchdistill.common.main_util\tCalling `CIFAR100` from `torchvision.datasets` with {'kwargs': {'root': '~/datasets/cifar100', 'train': True, 'download': True, 'transform': Compose(\n",
      "    RandomCrop(size=(32, 32), padding=4)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5070754, 0.48655024, 0.44091907], std=[0.26733398, 0.25643876, 0.2761503])\n",
      ")}}\n",
      "Files already downloaded and verified\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tGetting `ToTensor` from `torchvision.transforms`\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tCalling `ToTensor` from `torchvision.transforms` with {}\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tGetting `Normalize` from `torchvision.transforms`\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tCalling `Normalize` from `torchvision.transforms` with {'kwargs': {'mean': [0.5070754, 0.48655024, 0.44091907], 'std': [0.26733398, 0.25643876, 0.2761503]}}\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tGetting `Compose` from `torchvision.transforms`\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tCalling `Compose` from `torchvision.transforms` with {'kwargs': {'transforms': [ToTensor(), Normalize(mean=[0.5070754, 0.48655024, 0.44091907], std=[0.26733398, 0.25643876, 0.2761503])]}}\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tGetting `CIFAR100` from `torchvision.datasets`\n",
      "2024/11/19 12:56:58\tINFO\ttorchdistill.common.main_util\tCalling `CIFAR100` from `torchvision.datasets` with {'kwargs': {'root': '~/datasets/cifar100', 'train': False, 'download': True, 'transform': Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.5070754, 0.48655024, 0.44091907], std=[0.26733398, 0.25643876, 0.2761503])\n",
      ")}}\n",
      "Files already downloaded and verified\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.common.main_util\tGetting `RandomSampler` from `torch.utils.data`\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.common.main_util\tGetting `SequentialSampler` from `torch.utils.data`\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.common.main_util\tckpt file path is None\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.common.main_util\tckpt file path is None\n",
      "2024/11/19 12:56:59\tINFO\t__main__\tStart training\n",
      "/Users/revanth/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 10 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.core.distillation\t[teacher model]\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.models.util\tUsing the original model\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.core.distillation\t[student model]\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.models.util\tUsing the original model\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.core.distillation\tLoss = 1.0 * KDLoss(\n",
      "  (cross_entropy_loss): CrossEntropyLoss()\n",
      ")\n",
      "2024/11/19 12:56:59\tINFO\ttorchdistill.core.distillation\tFreezing the whole teacher model\n",
      "2024/11/19 12:57:28\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [  0/782]  eta: 6:14:41  lr: 0.1  img/s: 24.22046882613011  loss: 4.7223 (4.7223)  time: 28.7487  data: 26.0820\n",
      "2024/11/19 12:58:10\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [100/782]  eta: 0:07:59  lr: 0.1  img/s: 147.05383683672224  loss: 4.2493 (4.4151)  time: 0.4212  data: 0.0004\n"
     ]
    }
   ],
   "source": [
    "!python examples/torchvision/image_classification.py --config configs/densenet_from_wide_resnet.yaml --run_log log/test2.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a3a55-5a16-4210-a30e-ce5a44f085d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
